# 방법론 평가

검증 방법론에 대한 비판적 검토와 학술 연구 결과를 다룹니다.

---

## Q13: 이 프로젝트의 검증 방법론에 대한 비판과 학술 연구 결과는?

**질문 시각**: 2026-01-05

**답변**:

"vocab_size나 config dimension 비교만으로는 불충분하고, 실제 토큰 중복률이나 weight 값 비교가 더 중요하다"는 의견이 제기되었습니다. 이에 대해 학술 연구를 조사한 결과를 공유합니다.

학술적으로 가장 신뢰할 수 있는 검증 방법은 무엇일까요? arXiv:2502.00706v1에 발표된 "Model Provenance Testing for Large Language Models" 논문에 따르면, 600개 이상의 모델에서 검증된 결과 출력 행동 기반 통계 분석이 가장 신뢰할 수 있는 방법입니다. 동일 프롬프트에 대한 출력 토큰 일치율을 통계 분석하는 black-box output similarity 방법이 90-95% precision과 80-90% recall을 달성했습니다. Config 비교는 불충분한데, fine-tuning은 architecture를 보존하기 때문입니다. Weight 비교는 유효하지만 white-box 접근이 필요합니다.

Config나 dimension 비교에는 한계가 있습니다. config.json 비교의 한계는 fine-tuning이 architecture를 보존하므로 동일한 dimension을 가진 모델이 파생작일 수 있다는 점입니다. vocab_size 비교의 경우, fine-tuning 시 tokenizer를 그대로 사용하므로 vocab_size 일치가 오히려 파생 증거가 될 수 있습니다.

그렇다면 현재 프로젝트 방법론의 유효성은 어떨까요? 현재 프로젝트의 로직은 "vocab_size가 불일치하면 from scratch 지지"입니다. vocab_size가 다르면 tokenizer 재학습이 필요하므로 from scratch의 강력한 증거가 됩니다. 이 로직은 유효합니다. 반면 vocab_size가 같으면 추가 검증이 필요한데, token 중복률과 merge rules를 분석해야 합니다. 따라서 vocab_size 불일치를 기반으로 한 Solar, A.X-K1, VAETKI, K-EXAONE의 판정은 여전히 유효합니다. HyperCLOVAX처럼 vocab_size가 유사한 경우에는 실제 토큰 중복률 분석이 추가로 필요합니다.

Yi-Llama 논란 사례도 참고할 만합니다. 01.AI의 Yi-34B 모델이 Meta Llama에서 파생되었다는 의혹이 있었습니다. Architecture가 Llama와 동일한 구조였고, tensor names도 Llama 형식을 그대로 사용했습니다. 01.AI는 이를 "oversight(실수)"라고 인정했습니다. 하지만 weight 복사 증거는 없었고 독립 학습 주장을 유지했습니다. EleutherAI의 분석에 따르면, Yi는 독립적으로 학습되었으며 Llama architecture 채택은 업계 표준 관행입니다.

방법론 개선 방향을 정리하면, vocab_size 비교에 실제 토큰 중복률 계산을 추가하고, config dimension 비교에 출력 행동 유사도 분석을 추가하면 됩니다. Architecture 비교는 유효한데, architecture가 다르면 weight 재사용이 불가능하기 때문입니다.

비판의 타당성을 평가하면, "config dimension 비교만으로 불충분"하다는 주장은 부분적으로 맞습니다. 같은 architecture에서 fine-tuning이 가능하기 때문입니다. "실제 토큰 중복률이 더 중요"하다는 주장은 맞는데, 특히 vocab_size가 유사할 때 그렇습니다. "weight 비교가 더 중요"하다는 주장은 부분적으로 맞지만, 학술 연구에서는 output behavior가 더 신뢰성 있는 것으로 나타났습니다.

현재 프로젝트 판정의 유효성을 정리하면, vocab_size가 명확히 다른 모델들인 Solar, A.X-K1, VAETKI, K-EXAONE의 판정은 유효합니다. vocab_size가 유사한 HyperCLOVAX는 추가 검증을 권장합니다.

---

<!-- SECTION_MARKER: 새로운 방법론 평가 Q&A는 이 마커 위에 추가됩니다 -->
